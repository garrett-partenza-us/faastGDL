{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import os\n",
    "import javalang\n",
    "from javaprep import *\n",
    "from edge_index import edges\n",
    "import os\n",
    "from loaders import get_loaders, get_trees\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, seed):\n",
    "        torch.manual_seed(seed)\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(50, 64)\n",
    "        self.conv2 = GCNConv(64, 64)\n",
    "        self.conv3 = GCNConv(64, 64)\n",
    "        self.lin = Linear(64, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(train, test, cwe):\n",
    "    \n",
    "    seed = random.randint(1,10000)\n",
    "    model = GCN(seed)\n",
    "    learning_rate = 0.01\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = loss_function\n",
    "    current_time = (datetime.now()).strftime(\"%H:%M:%S\")\n",
    "    current_date = (date.today()).strftime(\"%d/%m/%Y\")\n",
    "    epochs, losses, test_accs, train_accs, precisions, recalls, fscores = [], [], [], [], [], [], []\n",
    "    score_report = {\n",
    "        'Test Acc': [], \n",
    "        'Losses': [],\n",
    "        'FScores': [],\n",
    "        'Recalls': [],\n",
    "        'Precisions': [],\n",
    "        'CWE': cwe, \n",
    "        'Model': str(model).replace('\\n', ' ').replace('\\t', ' '), \n",
    "        'Date': current_date, \n",
    "        'Time': current_time, \n",
    "        'Seed': seed, \n",
    "        'Learning Rate': learning_rate, \n",
    "        'Loss Function': loss_function\n",
    "    }\n",
    "    epochs_no_improve = 0\n",
    "    saved = False\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.08)\n",
    "    for epoch in range(40):\n",
    "        print(\"Epoch: \", epoch, end='\\r')\n",
    "        track = []\n",
    "        for data in train:   \n",
    "            optimizer.zero_grad()  \n",
    "            out = model(data.x, data.edge_index, data.batch)  \n",
    "            loss = criterion(out, data.y)\n",
    "            pred = out.argmax(dim=1)\n",
    "            loss.backward()  \n",
    "            optimizer.step()\n",
    "            track.append(round(metrics.accuracy_score(data.y.tolist(), pred.tolist()), 3))\n",
    "        train_accs.append(statistics.mean(track))\n",
    "        scheduler.step()\n",
    "        track_a, track_p, track_r, track_f = [],[],[],[]\n",
    "        for quiz in test:\n",
    "            out = model(quiz.x, quiz.edge_index, quiz.batch) \n",
    "            pred = out.argmax(dim=1)\n",
    "            track_a.append(metrics.accuracy_score(quiz.y.tolist(), pred.tolist()))\n",
    "            track_p.append(metrics.precision_score(quiz.y.tolist(), pred.tolist(), zero_division=0))\n",
    "            track_r.append(metrics.recall_score(quiz.y.tolist(), pred.tolist(), zero_division=0))\n",
    "            track_f.append(metrics.f1_score(quiz.y.tolist(), pred.tolist(), zero_division=0))\n",
    "        test_accs.append(statistics.mean(track_a))\n",
    "        precisions.append(statistics.mean(track_p))\n",
    "        recalls.append(statistics.mean(track_r))\n",
    "        fscores.append(statistics.mean(track_f))\n",
    "        epochs.append(epoch)\n",
    "        losses.append(loss)\n",
    "        if epoch+1 in [1,3,5,10,20,40]:\n",
    "            score_report['Test Acc'].append(statistics.mean(track_a))\n",
    "            score_report['Losses'].append(round(loss.item(), 3))\n",
    "            score_report['FScores'].append(statistics.mean(track_f))\n",
    "            score_report['Recalls'].append(statistics.mean(track_r))\n",
    "            score_report['Precisions'].append(statistics.mean(track_p))\n",
    "        \n",
    "        \n",
    "    plt.figure(figsize=(20,10))\n",
    "    x_ticks = np.arange(0, 40, 5)\n",
    "    plt.xticks(x_ticks)\n",
    "    y_ticks = np.arange(0, 1, 0.1)\n",
    "    plt.yticks(y_ticks)\n",
    "    plt.plot(epochs, losses, label='train loss', color='darkviolet', linewidth=2)\n",
    "    plt.plot(epochs, train_accs, label='train acc', color='gold', linewidth=2)\n",
    "    plt.plot(epochs, test_accs, label='test acc', color='forestgreen', linewidth=2)\n",
    "    plt.plot(epochs, precisions, label='precision', color='dodgerblue', linewidth=2)\n",
    "    plt.plot(epochs, recalls, label='recall', color='gray', linewidth=2)\n",
    "    plt.plot(epochs, fscores, label='f-score', color='crimson', linewidth=2)\n",
    "    plt.legend(prop={'size': 20})\n",
    "    plt.savefig('../pngs/OWASP-'+str(cwe)+'-'+str(current_date).replace('/','-')+'-'+str(current_time)+'.png')\n",
    "    plt.clf()\n",
    "    print()\n",
    "                                             \n",
    "    return score_report, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating asts...\n",
      "creating trees...\n"
     ]
    }
   ],
   "source": [
    "vocabdict, treedict = get_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning on CWE22...\n",
      "22\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  1706  Number of bad methods:  1706\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "22\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  1706  Number of bad methods:  1706\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "22\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  1706  Number of bad methods:  1706\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "[22, '28/12/2020', '09:43:16', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 9945, 0.01, CrossEntropyLoss(), 0.771823347107438, 0.8413872446626457, 0.7189563777414097, 0.6415943676128731, 0.8327737603305785, 0.8821337753155936, 0.8066853751459788, 0.7538165611712614, 0.8766787190082644, 0.8708726549195871, 0.8681865929444778, 0.8799710578066896, 0.9034090909090909, 0.8426316967268276, 0.9024728170958953, 0.9780279296726665, 0.9545454545454546, 0.9678747037510759, 0.9532028761666702, 0.940684051500615, 0.9474431818181818, 0.9635876564018275, 0.9422540455308994, 0.9242817038482674]\n",
      "Learning on CWE78...\n",
      "78\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  1802  Number of bad methods:  1802\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "78\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  1802  Number of bad methods:  1802\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "78\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  1802  Number of bad methods:  1802\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "[78, '28/12/2020', '10:01:32', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 9374, 0.01, CrossEntropyLoss(), 0.6635230179028133, 0.6227418211056801, 0.6890162746312376, 0.7833772117339892, 0.7587915601023018, 0.867520824586042, 0.7026787041287317, 0.6020062844231642, 0.8455882352941176, 0.9574661272231605, 0.8147574827106181, 0.7205340411222764, 0.9267902813299232, 0.8834595812130239, 0.9276782179354051, 0.9793602355303123, 0.9418957800511509, 0.9447983646900056, 0.9366344301600728, 0.9320207037918036, 0.9461317135549873, 0.9558363959965791, 0.9427903445275853, 0.9335138965893441]\n",
      "Learning on CWE79...\n",
      "79\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  1909  Number of bad methods:  1909\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "79\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  1909  Number of bad methods:  1909\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "79\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  1909  Number of bad methods:  1909\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "[79, '28/12/2020', '10:27:05', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 2173, 0.01, CrossEntropyLoss(), 0.5398065476190477, 0.5060466959105342, 0.6287629120861444, 0.8503023226272065, 0.6668526785714286, 0.6069592237124039, 0.6959616400943738, 0.8357674575166836, 0.7972470238095238, 0.7876689010880187, 0.7652493584105008, 0.7495439027704894, 0.8329613095238095, 0.8122644489082183, 0.8178090850685668, 0.8329301498080522, 0.8379836309523809, 0.8159131252591005, 0.8241586813979099, 0.8390522514264774, 0.8316592261904762, 0.8241398887490219, 0.8129457787769305, 0.8094843826122851]\n",
      "Learning on CWE89...\n",
      "89\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  2297  Number of bad methods:  2297\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "89\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  2297  Number of bad methods:  2297\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "89\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  2297  Number of bad methods:  2297\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "[89, '28/12/2020', '11:02:13', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 5719, 0.01, CrossEntropyLoss(), 0.548819340329835, 0.5286807784156371, 0.6808865153105217, 0.981001486436269, 0.9211488005997002, 0.9559005565090758, 0.9170294592414022, 0.8860810617213762, 0.9495877061469266, 1.0, 0.9484037133832256, 0.9048276408127829, 0.939233508245877, 0.9544504937253416, 0.9384293821554147, 0.9268650357115412, 0.938811844077961, 0.9533678352950798, 0.9398765744674429, 0.929926950132482, 0.9495877061469266, 0.98840200536448, 0.9485209301956907, 0.9144504554558816]\n",
      "Learning on CWE90...\n",
      "90\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "balancing dataset (pass 2)\n",
      "Number of good methods:  521  Number of bad methods:  521\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "90\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "balancing dataset (pass 2)\n",
      "Number of good methods:  521  Number of bad methods:  521\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "90\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "balancing dataset (pass 2)\n",
      "Number of good methods:  521  Number of bad methods:  521\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "[90, '28/12/2020', '11:10:45', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 7107, 0.01, CrossEntropyLoss(), 0.6152836134453782, 0.5979734317969612, 0.6587222794068833, 0.7450549450549451, 0.6617647058823529, 0.8222789115646258, 0.5315974902546831, 0.40650619222047796, 0.7639180672268907, 0.8099626563912279, 0.7367225192883792, 0.6936159079016222, 0.790703781512605, 0.8617979242979243, 0.7673628513743261, 0.7012210012210012, 0.8040966386554622, 0.944047619047619, 0.768819981568446, 0.6576835862550148, 0.8403361344537815, 0.9180533751962323, 0.8246205262487821, 0.7569684283969998]\n",
      "Learning on CWE327...\n",
      "327\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "Number of good methods:  720  Number of bad methods:  720\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "327\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "Number of good methods:  720  Number of bad methods:  720\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "327\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "Number of good methods:  720  Number of bad methods:  720\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "[327, '28/12/2020', '11:20:45', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 3252, 0.01, CrossEntropyLoss(), 0.5520833333333334, 0.5202380952380952, 0.3045726415291633, 0.21776817953288544, 0.5416666666666666, 0.0, 0.0, 0.0, 0.6145833333333334, 0.8574074074074074, 0.3231567480793487, 0.2051501058854, 0.5798611111111112, 0.5665003206669873, 0.45402805646576305, 0.3966110958758018, 0.6840277777777778, 0.7761183261183261, 0.5621074833953044, 0.45046734311440195, 0.6805555555555556, 0.6845376845376845, 0.6002840038880083, 0.5395087755381873]\n",
      "Learning on CWE328...\n",
      "328\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  714  Number of bad methods:  714\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "328\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  714  Number of bad methods:  714\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "328\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  714  Number of bad methods:  714\n",
      "splitting dataset\n",
      "Epoch:  39\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gparte1/.local/lib/python3.6/site-packages/ipykernel_launcher.py:64: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[328, '28/12/2020', '11:27:20', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 1008, 0.01, CrossEntropyLoss(), 0.5099537037037037, 0.49216637272192826, 0.5927233367206577, 0.7627461690929183, 0.4648148148148148, 0.4695041816009558, 0.6259584464136666, 0.9573481214348087, 0.4756944444444444, 0.44784567284567284, 0.46307155394376487, 0.49524625414718293, 0.5314814814814814, 0.5526455026455026, 0.23232121335836506, 0.15399562884083007, 0.5344907407407408, 0.5087126542548831, 0.6404357790695977, 0.8860820194024529, 0.4965277777777778, 0.4850953254209959, 0.6075204918301591, 0.833280253171894]\n",
      "Learning on CWE330...\n",
      "330\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  2028  Number of bad methods:  2028\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "[330, '28/12/2020', '11:36:26', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 3757, 0.01, CrossEntropyLoss(), 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Learning on CWE501...\n",
      "501\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "balancing dataset (pass 2)\n",
      "Number of good methods:  505  Number of bad methods:  505\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "501\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "balancing dataset (pass 2)\n",
      "Number of good methods:  505  Number of bad methods:  505\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "501\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "balancing dataset (pass 2)\n",
      "Number of good methods:  505  Number of bad methods:  505\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "[501, '28/12/2020', '11:47:04', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 8781, 0.01, CrossEntropyLoss(), 0.6080357142857142, 0.5710626319493315, 0.691439199434695, 0.8924944336709042, 0.7571428571428571, 0.7941043083900227, 0.7399409763905562, 0.7024491848021259, 0.725, 0.6897481799737438, 0.7522124981207138, 0.854725992961287, 0.8116071428571429, 0.987012987012987, 0.7807045621363117, 0.6499928176398765, 0.8973214285714286, 0.9220330237358101, 0.902976032793477, 0.8904582345758817, 0.8964285714285715, 0.8966736694677871, 0.8952908436101713, 0.9093837535014005]\n",
      "Learning on CWE614...\n",
      "614\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  215  Number of bad methods:  215\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "[614, '28/12/2020', '11:49:03', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 8178, 0.01, CrossEntropyLoss(), 0.5104166666666666, 0.6349206349206349, 0.36822966507177035, 0.25997150997151, 0.42803030303030304, 0.16666666666666666, 0.03333333333333333, 0.018518518518518517, 0.5, 0.5888888888888889, 0.39676113360323884, 0.30163817663817666, 0.865530303030303, 0.8055555555555556, 0.8915343915343915, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Learning on CWE643...\n",
      "643\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  217  Number of bad methods:  217\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "643\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  217  Number of bad methods:  217\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "643\n",
      "training word2vec...\n",
      "creating graphs..\n",
      "balancing dataset (pass 1)\n",
      "Number of good methods:  217  Number of bad methods:  217\n",
      "splitting dataset\n",
      "Epoch:  39\n",
      "[643, '28/12/2020', '11:51:30', 'GCN(   (conv1): GCNConv(50, 64)   (conv2): GCNConv(64, 64)   (conv3): GCNConv(64, 64)   (lin): Linear(in_features=64, out_features=2, bias=True) )', 5978, 0.01, CrossEntropyLoss(), 0.5095108695652174, 0.5888888888888889, 0.47130647130647135, 0.3942307692307692, 0.5135869565217391, 0.9333333333333333, 0.261559696342305, 0.15897435897435896, 0.7133152173913043, 0.8277777777777777, 0.7015451341827053, 0.6163461538461539, 0.7341485507246377, 0.8452380952380952, 0.7206349206349206, 0.6330128205128205, 0.7404891304347826, 0.8216619981325863, 0.7367731367731367, 0.6705128205128206, 0.8152173913043478, 0.9568151147098516, 0.7940806924472986, 0.7038461538461539]\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vulnerabilities = [22,78,79,89,90,327,328,330,501,614,643]\n",
    "for cwe in vulnerabilities:\n",
    "    try:\n",
    "        print(\"Learning on CWE\"+str(cwe)+\"...\")\n",
    "        current_time = (datetime.now()).strftime(\"%H:%M:%S\")\n",
    "        current_date = (date.today()).strftime(\"%d/%m/%Y\")\n",
    "        models = []\n",
    "        ending_acc = []\n",
    "        sps = []\n",
    "        for i in range(3):\n",
    "            train, test = get_loaders(cwe, \"owasp\", vocabdict, treedict)\n",
    "            score_report, model = learn(train, test, cwe)\n",
    "            ending_acc.append(score_report['Test Acc'][-1])\n",
    "            models.append(model)\n",
    "            sps.append(score_report)\n",
    "            if max(ending_acc) == 1:\n",
    "                break\n",
    "        best_run = ending_acc.index(max(ending_acc))\n",
    "        score_report = sps[best_run]\n",
    "        model = models[best_run]\n",
    "        torch.save(model.state_dict(), '../models/OWASP-'+str(cwe)+'-'+(current_date).replace('/','')+'-'+current_time.replace('/',''))\n",
    "        row = [\n",
    "            score_report['CWE'],\n",
    "            score_report['Date'],\n",
    "            score_report['Time'],\n",
    "            score_report['Model'],\n",
    "            score_report['Seed'],\n",
    "            score_report['Learning Rate'],\n",
    "            score_report['Loss Function'],\n",
    "        ]\n",
    "        for epoch in zip(score_report['Test Acc'], score_report['Precisions'], score_report['FScores'], score_report['Recalls']):\n",
    "            for item in epoch:\n",
    "                row.append(item)\n",
    "        print(row)       \n",
    "        with open('../owasp_score_report.csv','a') as fd:\n",
    "            writer = csv.writer(fd)\n",
    "            writer.writerow(row)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"failed cwe \"+str(cwe))\n",
    "        pass\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faast",
   "language": "python",
   "name": "faast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
